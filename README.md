# ğŸ¥ Kara Medical Data Pipeline â€“ Week 7 Challenge

This project delivers an end-to-end data pipeline for analyzing Ethiopian medical business activity using public Telegram channels.

## ğŸ“¦ Project Overview

- **Source**: Public Telegram Channels (e.g., @lobelia4cosmetics, @tikvahpharma)
- **Objective**: Scrape messages and media from Telegram, store as raw JSON, load into PostgreSQL, and transform using dbt
- **Tools**:
  - Telethon (scraping)
  - PostgreSQL + Docker
  - dbt (data transformation)
  - Dagster (orchestration)
  - YOLOv8 (image enrichment â€“ Task 3)
  - FastAPI (analytical API â€“ Task 4)

---

## âœ… Tasks Completed

### âœ… Task 0 â€“ Project Setup

- Git repository initialized
- Dockerized Python + PostgreSQL environment
- `.env` secrets management and `.gitignore` used
- `requirements.txt` for dependencies

### âœ… Task 1 â€“ Telegram Scraping and Data Collection

- Scraped messages from:
  - `@lobelia4cosmetics`
  - `@tikvahpharma`
- Media downloaded (images)
- Data stored in structured folders like:
- âœ… **Sample JSON files** included:
- [`tikvah_sample.json`](data/raw/telegram_messages/2025-07-12/tikvahpharma/messages.json)
- [`lobelia_sample.json`](data/raw/telegram_messages/2025-07-12/lobelia4cosmetics/messages.json)

### âœ… Task 2 â€“ Data Modeling with dbt

- Loaded raw JSON into PostgreSQL (`raw.telegram_messages`)
- Created dbt models:
- `stg_telegram_messages` (staging)
- `dim_channels`, `dim_dates` (dimensions)
- `fct_messages` (fact table with 28M+ messages, 13M+ media)
- dbt tests: `unique`, `not_null`, and custom checks
- dbt docs generated

---

## ğŸ“‚ Project Structure

Kara_Medical-Data_Pipeline/
â”‚
â”œâ”€â”€ data/ # Raw and sample Telegram message data
â”‚ â””â”€â”€ raw/
â”‚ â””â”€â”€ telegram_messages/
â”‚ â””â”€â”€ 2025-07-12/
â”‚ â”œâ”€â”€ lobelia4cosmetics/
â”‚ â”‚ â””â”€â”€ messages_sample.json
â”‚ â”œâ”€â”€ tikvahpharma/
â”‚ â”‚ â””â”€â”€ messages_sample.json
â”‚
â”œâ”€â”€ kara_dbt/ # dbt project for modeling & transformation
â”‚ â”œâ”€â”€ dbt_project.yml # Main dbt project config
â”‚ â”œâ”€â”€ profiles.yml # DB connection config
â”‚ â””â”€â”€ models/
â”‚ â”œâ”€â”€ staging/
â”‚ â”‚ â”œâ”€â”€ stg_telegram_messages.sql
â”‚ â”‚ â””â”€â”€ schema.yml # Tests for staging models
â”‚ â””â”€â”€ marts/
â”‚ â”œâ”€â”€ dim_channels.sql
â”‚ â”œâ”€â”€ dim_dates.sql
â”‚ â”œâ”€â”€ fct_messages.sql
â”‚ â””â”€â”€ schema.yml # Tests for marts models
â”‚
â”œâ”€â”€ scripts/ # Core pipeline scripts
â”‚ â”œâ”€â”€ scrape_telegram.py # Telegram scraper (Telethon)
â”‚ â”œâ”€â”€ load_to_postgres.py # JSON to PostgreSQL loader
â”‚ â””â”€â”€ run_dbt.py # Wrapper for dbt run
â”‚
â”œâ”€â”€ logs/ # Pipeline logs
â”‚ â”œâ”€â”€ run_dbt.log # dbt execution log (small, committed)
â”‚ â”œâ”€â”€ load_to_postgres.log # Loader log (small, committed)
â”‚ â”œâ”€â”€ scrape_telegram.log # Scraper log (large, ignored)
â”‚ â””â”€â”€ dbt.log # Full dbt logs (large, ignored)
â”‚
â”œâ”€â”€ docs/ # GitHub Pages-ready dbt documentation
â”‚ â”œâ”€â”€ index.html # Entry point for dbt docs
â”‚ â”œâ”€â”€ catalog.json # dbt metadata
â”‚ â”œâ”€â”€ manifest.json # Model dependency map
â”‚ â””â”€â”€ ... other dbt static assets
â”‚
â”œâ”€â”€ .env.example # Sample env variables (safe to share)
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml # Docker services config (DB + App)
â”œâ”€â”€ Dockerfile # Python image for pipeline
â”œâ”€â”€ requirements.txt # Python packages
â””â”€â”€ README.md # Project overview and usage


##  How to Run This Project


# 1. Clone repo & configure secrets
cp .env.example .env

# 2. Start containers
docker-compose up -d

# 3. Run the Telegram scraper
python scripts/telegram_scraper.py

# 4. Load scraped data into Postgres
python scripts/load_to_postgres.py

# 5. Run dbt transformations
python scripts/run_dbt.py
