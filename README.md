# ğŸ¥ Kara Medical Data Pipeline â€“ Week 7 Challenge

This project delivers an end-to-end data pipeline for analyzing Ethiopian medical business activity using public Telegram channels.

## ğŸ“¦ Project Overview

- **Source**: Public Telegram Channels (e.g., @lobelia4cosmetics, @tikvahpharma)
- **Objective**: Scrape messages and media from Telegram, store as raw JSON, load into PostgreSQL, and transform using dbt
- **Tools**:
  - Telethon (scraping)
  - PostgreSQL + Docker
  - dbt (data transformation)
  - Dagster (orchestration)
  - YOLOv8 (image enrichment â€“ Task 3)
  - FastAPI (analytical API â€“ Task 4)

---

## âœ… Tasks Completed

### âœ… Task 0 â€“ Project Setup

- Git repository initialized
- Dockerized Python + PostgreSQL environment
- `.env` secrets management and `.gitignore` used
- `requirements.txt` for dependencies

### âœ… Task 1 â€“ Telegram Scraping and Data Collection

- Scraped messages from:
  - `@lobelia4cosmetics`
  - `@tikvahpharma`
- Media downloaded (images)
- Data stored in structured folders like:
- âœ… **Sample JSON files** included:
- [`tikvah_sample.json`](data/raw/telegram_messages/2025-07-12/tikvahpharma/messages.json)
- [`lobelia_sample.json`](data/raw/telegram_messages/2025-07-12/lobelia4cosmetics/messages.json)

### âœ… Task 2 â€“ Data Modeling with dbt

- Loaded raw JSON into PostgreSQL (`raw.telegram_messages`)
- Created dbt models:
- `stg_telegram_messages` (staging)
- `dim_channels`, `dim_dates` (dimensions)
- `fct_messages` (fact table with 28M+ messages, 13M+ media)
- dbt tests: `unique`, `not_null`, and custom checks
- dbt docs generated

---

## ğŸ“‚ Project Structure

``` Kara_Medical_Data_Pipeline/ â”œâ”€â”€ data/ â”‚ â””â”€â”€ raw/ â”‚ â””â”€â”€ telegram_messages/ â”‚ â””â”€â”€ 2025-07-12/ â”‚ â”œâ”€â”€ lobelia4cosmetics/ â”‚ â”‚ â””â”€â”€ messages.json â”‚ â”œâ”€â”€ tikvahpharma/ â”‚ â”‚ â””â”€â”€ messages.json â”‚ â”œâ”€â”€ kara_dbt/ â”‚ â”œâ”€â”€ models/ â”‚ â”‚ â”œâ”€â”€ staging/ â”‚ â”‚ â”‚ â””â”€â”€ stg_telegram_messages.sql â”‚ â”‚ â””â”€â”€ marts/ â”‚ â”‚ â”œâ”€â”€ dim_channels.sql â”‚ â”‚ â”œâ”€â”€ dim_dates.sql â”‚ â”‚ â””â”€â”€ fct_messages.sql â”‚ â”œâ”€â”€ dbt_project.yml â”‚ â””â”€â”€ profiles.yml â”‚ â”œâ”€â”€ logs/ â”‚ â”œâ”€â”€ scrape_telegram.log â”‚ â”œâ”€â”€ load_to_postgres.log â”‚ â””â”€â”€ run_dbt.log â”‚ â”œâ”€â”€ scripts/ â”‚ â”œâ”€â”€ scrape_telegram.py â”‚ â”œâ”€â”€ load_to_postgres.py â”‚ â””â”€â”€ run_dbt.py â”‚ â”œâ”€â”€ .env â”œâ”€â”€ .dockerignore â”œâ”€â”€ .gitignore â”œâ”€â”€ docker-compose.yml â”œâ”€â”€ README.md â””â”€â”€ requirements.txt ```

---

## ğŸš€ How to Run This Project


# 1. Clone repo & configure secrets
cp .env.example .env

# 2. Start containers
docker-compose up -d

# 3. Run the Telegram scraper
python scripts/telegram_scraper.py

# 4. Load scraped data into Postgres
python scripts/load_to_postgres.py

# 5. Run dbt transformations
python scripts/run_dbt.py
