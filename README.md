# ğŸ¥ Kara Medical Data Pipeline â€“ Week 7 Challenge

This project delivers an end-to-end data pipeline for analyzing Ethiopian medical business activity using public Telegram channels.

## ğŸ“¦ Project Overview

- **Source**: Public Telegram Channels (e.g., @lobelia4cosmetics, @tikvahpharma)
- **Objective**: Scrape messages and media from Telegram, store as raw JSON, load into PostgreSQL, and transform using dbt
- **Tools**:
  - Telethon (scraping)
  - PostgreSQL + Docker
  - dbt (data transformation)
  - Dagster (orchestration)
  - YOLOv8 (image enrichment â€“ Task 3)
  - FastAPI (analytical API â€“ Task 4)

---

## âœ… Tasks Completed

### âœ… Task 0 â€“ Project Setup

- Git repository initialized
- Dockerized Python + PostgreSQL environment
- `.env` secrets management and `.gitignore` used
- `requirements.txt` for dependencies

### âœ… Task 1 â€“ Telegram Scraping and Data Collection

- Scraped messages from:
  - `@lobelia4cosmetics`
  - `@tikvahpharma`
- Media downloaded (images)
- Data stored in structured folders like:
- âœ… **Sample JSON files** included:
- [`tikvah_sample.json`](data/raw/telegram_messages/2025-07-12/tikvahpharma/messages.json)
- [`lobelia_sample.json`](data/raw/telegram_messages/2025-07-12/lobelia4cosmetics/messages.json)

### âœ… Task 2 â€“ Data Modeling with dbt

- Loaded raw JSON into PostgreSQL (`raw.telegram_messages`)
- Created dbt models:
- `stg_telegram_messages` (staging)
- `dim_channels`, `dim_dates` (dimensions)
- `fct_messages` (fact table with 28M+ messages, 13M+ media)
- dbt tests: `unique`, `not_null`, and custom checks
- dbt docs generated

---

## ğŸ“‚ Project Structure

Kara_Medical_Data_Pipeline/
â”‚
â”œâ”€â”€ data/                               # Raw and sample Telegram message data
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ telegram_messages/
â”‚           â””â”€â”€ 2025-07-12/
â”‚               â”œâ”€â”€ lobelia4cosmetics/     # Sample scraped messages from Lobelia
â”‚               â”‚   â””â”€â”€ messages.json
â”‚               â”œâ”€â”€ tikvahpharma/          # Sample scraped messages from Tikvah Pharma
â”‚               â”‚   â””â”€â”€ messages.json
â”‚
â”œâ”€â”€ kara_dbt/                           # dbt project for data modeling and transformation
â”‚   â”œâ”€â”€ dbt_project.yml                 # Main dbt project config
â”‚   â”œâ”€â”€ profiles.yml                    # dbt connection config
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/                    # Staging models (cleaning and structuring)
â”‚       â”‚   â””â”€â”€ stg_telegram_messages.sql
â”‚       â””â”€â”€ marts/                      # Final star schema models
â”‚           â”œâ”€â”€ dim_channels.sql
â”‚           â”œâ”€â”€ dim_dates.sql
â”‚           â””â”€â”€ fct_messages.sql
â”‚
â”œâ”œâ”€â”€ logs/                               # Log files for scraping, loading, and dbt runs
â”‚   â”œâ”€â”€ scrape_telegram.log             # (Large, not tracked; sample available on demand)
â”‚   â”œâ”€â”€ dbt.log                         # (Large, not tracked)
â”‚   â”œâ”€â”€ run_dbt.log                     # (Small sample log)
â”‚   â””â”€â”€ load_to_postgres.log            # (Small sample log)

â”‚
â”œâ”€â”€ scripts/                            # Core pipeline scripts
â”‚   â”œâ”€â”€ scrape_telegram.py              # Scrapes Telegram channels
â”‚   â”œâ”€â”€ load_to_postgres.py             # Loads raw JSON into PostgreSQL
â”‚   â””â”€â”€ run_dbt.py                      # Runs dbt transformation
â”‚
â”œâ”€â”€ .env.example                        # Example environment variables
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml                 # Orchestrates services (PostgreSQL + app)
â”œâ”€â”€ Dockerfile                         # Python environment container
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md                          # Project overview and instructions



## ğŸš€ How to Run This Project


# 1. Clone repo & configure secrets
cp .env.example .env

# 2. Start containers
docker-compose up -d

# 3. Run the Telegram scraper
python scripts/telegram_scraper.py

# 4. Load scraped data into Postgres
python scripts/load_to_postgres.py

# 5. Run dbt transformations
python scripts/run_dbt.py
